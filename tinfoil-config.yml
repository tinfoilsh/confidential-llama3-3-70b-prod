shim-version: v0.1.9@sha256:410510c9e8e4c7489dd201fede302dee8455075ca28f4f0abbf84bded943b8f1
cvm-version: 0.1.3
ovmf-version: 0.0.2
cpus: 8
memory: 32768

models:
  - name: "llama3-3-70b"
    repo: "lambdalabs/Llama-3.3-70B-Instruct-AWQ-4bit@a70257cf10f368114a66115c315def76a1227e26"
    mpk: "06002d4871dbd882fc8b4c385e5181fdd85615e514f4efca3b6b3a3a774a36d2_39785426944_58b5d994-b471-58c9-8058-d224be115e1a"
vllm-args: --quantization awq_marlin --max-model-len 65536 --enable-auto-tool-choice --tool-call-parser llama3_json --chat-template /etc/tinfoil/templates/tool_chat_template_llama3.1_json.jinja

shim:
  listen-port: 443
  upstream-port: 8080
  control-plane: https://api.tinfoil.sh
  publish-attestation: true
  tls-challenge: dns
  paths:
    - /v1/chat/completions
    - /metrics
  origins:
    - https://tinfoil.sh
    - https://chat.tinfoil.sh
